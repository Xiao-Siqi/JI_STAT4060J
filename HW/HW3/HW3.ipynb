{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  rank\n",
       "0      0.0  380.0  3.61   3.0\n",
       "1      1.0  660.0  3.67   3.0\n",
       "2      1.0  800.0  4.00   1.0\n",
       "3      1.0  640.0  3.19   4.0\n",
       "4      0.0  520.0  2.93   4.0\n",
       "..     ...    ...   ...   ...\n",
       "395    0.0  620.0  4.00   2.0\n",
       "396    0.0  560.0  3.04   3.0\n",
       "397    0.0  460.0  2.63   2.0\n",
       "398    0.0  700.0  3.65   2.0\n",
       "399    0.0  600.0  3.89   3.0\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"admission.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    if np.all(x >= 0):\n",
    "        return 1.0/(1.0 + np.exp(-x))\n",
    "    else:\n",
    "        return np.exp(x)/(1.0 + np.exp(x))\n",
    "        \n",
    "\n",
    "def logistic_gradient_descent(xs, ys, num_iter, learning_rate):\n",
    "    x = xs.copy()\n",
    "    y = ys.copy()\n",
    "    np.random.seed(1)\n",
    "    r, c = x.shape\n",
    "    p = c \n",
    "    beta = 2 * np.random.randn(p, 1) - 1\n",
    "    epsilon = 1e-3\n",
    "    for i in range(num_iter):\n",
    "        pr = sigmoid(np.dot(x, beta))#400,4*4,1->400,1\n",
    "        beta = beta - learning_rate * np.dot(x.T,(pr-y))#4,1\n",
    "    return beta\n",
    "\n",
    "def acc(beta, xs, ys):\n",
    "    \"\"\" This function computes the accuracy on (xs, ys).\"\"\"\n",
    "    x = xs.copy()\n",
    "    y = ys.copy()\n",
    "    A = sigmoid(np.dot(x,beta))#400,4*4*1->400,1\n",
    "    m = A.shape[0]\n",
    "    Y_pred = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        if A[i,0]>0.5:\n",
    "            Y_pred[i,0] = 1\n",
    "        else:\n",
    "            Y_pred[i,0] = 0\n",
    "    return 1 - np.mean(np.abs(y-Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load data\"\"\"\n",
    "x = data[['gre','gpa','rank']]#(400,3)\n",
    "y = data[['admit']]#(400,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = x.shape\n",
    "xs = np.hstack((np.ones((r, 1)), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent_beta is [[ -11.34750435]\n",
      " [-120.56049022]\n",
      " [ -22.97188188]\n",
      " [-121.493096  ]] and accuracy is 0.6825\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Gradient Descent\"\"\"\n",
    "gradient_descent_beta = logistic_gradient_descent(xs, y, 2000, 0.001)\n",
    "acc_gds = acc(gradient_descent_beta,xs,y)\n",
    "print(\"gradient_descent_beta is\", gradient_descent_beta, \"and accuracy is\", np.array(acc_gds)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterated Reweighted Least Squares (IRLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" IRLS \"\"\"\n",
    "def logistic_IRLS(xs, ys, epsilon = 1e-6):\n",
    "    x = xs.copy()\n",
    "    y = ys.copy()\n",
    "    r, c = x.shape\n",
    "    beta = np.zeros((c, 1))\n",
    "    while True:\n",
    "        eta = np.dot(x, beta)\n",
    "        pr = sigmoid(eta)\n",
    "        w = pr * (1-pr)\n",
    "        z = eta + (y-pr) / w\n",
    "        sw = np.sqrt(w)\n",
    "        mw = np.repeat(sw, c, axis = 1)\n",
    "\n",
    "        x_work = mw * x\n",
    "        y_work = sw * z\n",
    "\n",
    "        beta_new, _, _, _ = np.linalg.lstsq(x_work, y_work,rcond=-1)\n",
    "        err = np.sum(np.abs(beta_new - beta))\n",
    "        beta = beta_new\n",
    "        if err < epsilon:\n",
    "            break\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRLS_beta is [[-3.44954869e+00]\n",
      " [ 2.29395940e-03]\n",
      " [ 7.77013676e-01]\n",
      " [-5.60031390e-01]] and accuracy is 0.7050000000000001\n"
     ]
    }
   ],
   "source": [
    "IRLS_beta = logistic_IRLS(xs,y)\n",
    "acc_irls = acc(IRLS_beta,xs,y)\n",
    "print(\"IRLS_beta is\", IRLS_beta, \"and accuracy is\", np.array(acc_irls)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the weight of Logistic Regression: [[-1.24085141  0.0021818   0.54729792 -0.57140469]]\n",
      "acc: 0.705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "x_train = xs#(400,3)\n",
    "y_train = data['admit']#(400,1)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(x_train, y_train)\n",
    "print('the weight of Logistic Regression:',clf.coef_)\n",
    "train_predict = clf.predict(x_train)\n",
    "print(\"acc:\", metrics.accuracy_score(y_train,train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: From the analysis above, we may find that the accuracy of Logistic regression using IRLS strategy is slightly higher than using Gradient descent, and is approximately equal to the accuracy using built-in Logistic Regression Function, indicating its rightness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, the coefficient of gpa using IRLS strategy is 7.77, which is a positive number and larger than the coefficient of gre. This means gpa is possibly much more important than gre grade, and the higher one gpa is, the larger probability he/she may be admitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of rank is -5.6, a negative number, which in another word, the larger the number in this category, the less likely one may be admitted, meaning that the higher prestige the student’s undergraduate insitution has, the more the student is likely to be admitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hypo = xs\n",
    "y_hypo = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>admit</td>      <th>  R-squared:         </th> <td>   0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 18 Oct 2022</td> <th>  Prob (F-statistic):</th> <td>1.05e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:12:47</td>     <th>  Log-Likelihood:    </th> <td> -241.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   491.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   396</td>      <th>  BIC:               </th> <td>   507.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.1824</td> <td>    0.217</td> <td>   -0.841</td> <td> 0.401</td> <td>   -0.609</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0004</td> <td>    0.000</td> <td>    2.106</td> <td> 0.036</td> <td> 2.94e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1510</td> <td>    0.063</td> <td>    2.383</td> <td> 0.018</td> <td>    0.026</td> <td>    0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1095</td> <td>    0.024</td> <td>   -4.608</td> <td> 0.000</td> <td>   -0.156</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>190.649</td> <th>  Durbin-Watson:     </th> <td>   1.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  51.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.667</td>  <th>  Prob(JB):          </th> <td>6.81e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.858</td>  <th>  Cond. No.          </th> <td>6.00e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  6e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   R-squared:                       0.096\n",
       "Model:                            OLS   Adj. R-squared:                  0.089\n",
       "Method:                 Least Squares   F-statistic:                     14.02\n",
       "Date:                Tue, 18 Oct 2022   Prob (F-statistic):           1.05e-08\n",
       "Time:                        19:12:47   Log-Likelihood:                -241.53\n",
       "No. Observations:                 400   AIC:                             491.1\n",
       "Df Residuals:                     396   BIC:                             507.0\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.1824      0.217     -0.841      0.401      -0.609       0.244\n",
       "x1             0.0004      0.000      2.106      0.036    2.94e-05       0.001\n",
       "x2             0.1510      0.063      2.383      0.018       0.026       0.276\n",
       "x3            -0.1095      0.024     -4.608      0.000      -0.156      -0.063\n",
       "==============================================================================\n",
       "Omnibus:                      190.649   Durbin-Watson:                   1.950\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.425\n",
       "Skew:                           0.667   Prob(JB):                     6.81e-12\n",
       "Kurtosis:                       1.858   Cond. No.                     6.00e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large,  6e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy\n",
    "from  scipy.stats import t,f\n",
    "results = sm.OLS(y_hypo,x_hypo).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hat = np.dot(np.dot(np.linalg.inv(np.dot(x_hypo.T,x_hypo)),x_hypo.T),y_hypo)\n",
    "y_hat = np.dot(x_hypo,beta_hat)\n",
    "y_mean = np.array(np.mean(y))\n",
    "sst = sum((np.array(y_hypo)-y_mean)**2)\n",
    "ssr = sum((y_hat-y_mean)**2)\n",
    "sse = sum(results.resid**2)\n",
    "R_squared =1 - sse/sst\n",
    "adjR_squared =1- (sse/(100-3-1))/(sst/(100-1))#1-(残差的平方和/残差的自由度)/(总平方和/无偏估计)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard error of gre 0.00043\n",
      "beta_gre t-value: 1.0369\n",
      "P>|t|: 0.30242\n"
     ]
    }
   ],
   "source": [
    "C = np.linalg.inv(np.dot(x_hypo.T,x_hypo))\n",
    "C_diag = np.diag(C)\n",
    "sigma_unb= (sse/(100-3-1))**(1/2)\n",
    "stderr_gre = sigma_unb*(C_diag[1]**(1/2))\n",
    "stderr_gre\n",
    "print('standard error of gre',round(stderr_gre,5))\n",
    "\"\"\" Hypothesis0: beta1 = 0\"\"\"\n",
    "t_gre = beta_hat[1]/stderr_gre\n",
    "print('beta_gre t-value:',round(t_gre[0],5))\n",
    "p_t1 = 2*t.sf(t_gre,95)\n",
    "print(\"P>|t|:\",round(p_t1[0],5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the hypothesis test (T-test) above, we may conclude taht we cannot reject the hypothethis0, meaning the model is not that significant, since p_t1>0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "      <th>x0_1.0</th>\n",
       "      <th>x0_2.0</th>\n",
       "      <th>x0_3.0</th>\n",
       "      <th>x0_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  rank  x0_1.0  x0_2.0  x0_3.0  x0_4.0\n",
       "0      0.0  380.0  3.61   3.0     0.0     0.0     1.0     0.0\n",
       "1      1.0  660.0  3.67   3.0     0.0     0.0     1.0     0.0\n",
       "2      1.0  800.0  4.00   1.0     1.0     0.0     0.0     0.0\n",
       "3      1.0  640.0  3.19   4.0     0.0     0.0     0.0     1.0\n",
       "4      0.0  520.0  2.93   4.0     0.0     0.0     0.0     1.0\n",
       "..     ...    ...   ...   ...     ...     ...     ...     ...\n",
       "395    0.0  620.0  4.00   2.0     0.0     1.0     0.0     0.0\n",
       "396    0.0  560.0  3.04   3.0     0.0     0.0     1.0     0.0\n",
       "397    0.0  460.0  2.63   2.0     0.0     1.0     0.0     0.0\n",
       "398    0.0  700.0  3.65   2.0     0.0     1.0     0.0     0.0\n",
       "399    0.0  600.0  3.89   3.0     0.0     0.0     1.0     0.0\n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OHEnc = OneHotEncoder()\n",
    "OHEnc.fit(data[[\"rank\"]])\n",
    "OHEnc_col = pd.DataFrame(OHEnc.transform(data[[\"rank\"]]).todense(), columns = OHEnc.get_feature_names(), index = data.index)\n",
    "data_new = data\n",
    "data_new = data_new.join(OHEnc_col)\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ohe = data_new[['gre','gpa','x0_1.0','x0_2.0','x0_3.0','x0_4.0']]\n",
    "r_ohe, c_ohe = x.shape\n",
    "xs_ohe = np.hstack((np.ones((r_ohe, 1)), x_ohe))\n",
    "y_ohe = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent_beta_ohe is [[-34.77040308]\n",
      " [-13.00811428]\n",
      " [-58.17820767]\n",
      " [ 66.0840369 ]\n",
      " [ 19.93979863]\n",
      " [-73.91576337]\n",
      " [-54.65574181]] and accuracy is 0.6825\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Gradient Descent\"\"\"\n",
    "gradient_descent_beta_ohe = logistic_gradient_descent(xs_ohe, y_ohe, 5500, 0.001)\n",
    "acc_gds_ohe = acc(gradient_descent_beta_ohe,xs_ohe,y)\n",
    "print(\"gradient_descent_beta_ohe is\", gradient_descent_beta_ohe, \"and accuracy is\", np.array(acc_gds_ohe)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRLS_beta_ohe is [[-3.90540561e+00]\n",
      " [ 2.26442569e-03]\n",
      " [ 8.04037654e-01]\n",
      " [-8.45737676e-02]\n",
      " [-7.60016698e-01]\n",
      " [-1.42477770e+00]\n",
      " [-1.63603744e+00]] and accuracy is 0.71\n"
     ]
    }
   ],
   "source": [
    "\"\"\" IRLS \"\"\"\n",
    "IRLS_beta_ohe = logistic_IRLS(xs_ohe,y_ohe)\n",
    "acc_irls_ohe = acc(IRLS_beta_ohe,xs_ohe,y_ohe)\n",
    "print(\"IRLS_beta_ohe is\", IRLS_beta_ohe, \"and accuracy is\", np.array(acc_irls_ohe)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the accuracy of two models I derived, both of them have the accuracy of around 70%, which means they have relatively the same ability to fit the data. Using One-Hot Encoding has slightly higher performance, but can be ignored. \n",
    "In addition, both models' coefficient point to the assumption that the admission may be decided affected by gpa, gre and school rank. The higher gpa, gre and your undergraduate insitution's prestige you enjoy, the more likely you will be admitted. Gpa is much more improtant than gre score.\n",
    "However, from the hypothesis test, the factor gre is not significant, meaning it may not be so important to the admission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
